import os, json, time, threading, socket, signal, sys, atexit
import cv2, cv2.aruco as aruco, numpy as np
from flask import Flask, Response
from pymycobot.mycobot280 import MyCobot280
from pymycobot.error import MyCobot280DataException
import os
import psutil
import subprocess

import os, sys
import cv2

# 로그 완전 차단
try:
    cv2.utils.logging.setLogLevel(cv2.utils.logging.LOG_LEVEL_SILENT)
except Exception:
    os.environ["OPENCV_LOG_LEVEL"] = "SILENT"
    sys.stderr = open(os.devnull, 'w')  # stderr도 차단 (경고 메시지까지 완전히)


def cleanup():
    global cap
    if cap and cap.isOpened():
        cap.release()
        print("[종료] 카메라 연결 해제 완료")

    # ✅ 포트 점유 프로세스 종료 (9816)
    try:
        for proc in psutil.process_iter(['pid', 'name', 'connections']):
            for conn in proc.info.get('connections', []):
                if conn.laddr and conn.laddr.port == 9816:
                    print(f"[포트 종료] PID={proc.pid} ({proc.name()}) 종료")
                    proc.kill()
                    break
    except Exception as e:
        print(f"[경고] 포트 종료 중 예외 발생: {e}")

    # ✅ 카메라 장치 점유 프로세스 종료
    try:
        output = subprocess.check_output("lsof /dev/video0", shell=True).decode()
        lines = output.strip().split('\n')[1:]
        for line in lines:
            pid = int(line.split()[1])
            print(f"[카메라 종료] PID={pid} 종료")
            os.kill(pid, 9)
    except subprocess.CalledProcessError:
        print("[카메라 종료] 점유 중인 프로세스 없음 (정상)")
    except Exception as e:
        print(f"[경고] 카메라 종료 중 예외 발생: {e}")


# ─── 종료 시그널 등록 ──────────────────────────────────────
signal.signal(signal.SIGINT, lambda sig, frame: cleanup() or sys.exit(0))
signal.signal(signal.SIGTERM, lambda sig, frame: cleanup() or sys.exit(0))
atexit.register(cleanup)

# 설정값
CAL_FILE = 'calibration.json'
DEFAULT_DT = [33.406, 19.536, 246.961]

# CAM_MTX = np.array([[596.69786411, 0.0, 282.61945091],
#                     [0.0, 592.93061262, 286.6451617 ],
#                     [0.0, 0.0, 1.0]])
# DIST_COEFFS = np.array([[-0.09849766, -0.15976911, -0.00334536, 0.00705238, 0.22717466]])


# ✅ 새 카메라 행렬
CAM_MTX = np.array([
    [2736.98231, 0.0, 320.553729],
    [0.0, 2730.38853, 234.335302],
    [0.0, 0.0, 1.0]
])

# ✅ 새 왜곡 계수
DIST_COEFFS = np.array([[-2.09578526, -43.8402559, -0.0176765795, -0.0463219652, 511.115001]])



if os.path.exists(CAL_FILE):
    try:
        with open(CAL_FILE) as f:
            DT = np.array(json.load(f)['T_CAM2BASE_STATIC'], float)
    except (KeyError, json.JSONDecodeError):
        print("⚠️ 'T_CAM2BASE_STATIC' 누락 → 기본값 사용")
        DT = np.array(DEFAULT_DT, float)
else:
    DT = np.array(DEFAULT_DT, float)

T_TOOL2CAM = np.array([0, 00, 0.0]) #55 13
MARKER_LEN = 35.0
MIN_Z, MAX_Z = 130.0, 450.0

FAST_SPEED = 50
SLOW_SPEED = 12
BLEND_MODE = 1

BASIC_POSE = [0, 0, -90, 0, 0, -45]
POSE2 = [30, 0, -90, 0, 0, -45]

ARUCO_DICT = aruco.getPredefinedDictionary(aruco.DICT_5X5_50)
ARUCO_PARAMS = aruco.DetectorParameters()

app = Flask(__name__)
latest_frame = None
lock = threading.Lock()
cap = None

def save_calib():
    with open(CAL_FILE, 'w') as f:
        json.dump({'T_CAM2BASE_STATIC': DT.tolist()}, f, indent=2)
    print(f"[저장] ΔT = {[round(x, 3) for x in DT]}")

def local_ip():
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    s.connect(("8.8.8.8", 9816))
    ip = s.getsockname()[0]
    s.close()
    return ip

@app.route('/')
def index():
    return "<h1>JetCobot</h1><img src='/video_feed'>"

@app.route('/video_feed')
def video_feed():
    def gen():
        global latest_frame
        while True:
            try:
                with lock:
                    fr = latest_frame.copy() if latest_frame is not None else None
                if fr is None:
                    time.sleep(0.03)
                    continue

                gray = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)
                corners, ids, _ = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMS)
                if ids is not None:
                    aruco.drawDetectedMarkers(fr, corners, ids)
                    c = corners[0][0]
                    cx, cy = int(c[:, 0].mean()), int(c[:, 1].mean())
                    cv2.circle(fr, (cx, cy), 6, (0, 0, 255), -1)

                    # ✅ 카메라 좌표 표시
                    objp = np.array([
                        [-MARKER_LEN / 2, MARKER_LEN / 2, 0],
                        [MARKER_LEN / 2, MARKER_LEN / 2, 0],
                        [MARKER_LEN / 2, -MARKER_LEN / 2, 0],
                        [-MARKER_LEN / 2, -MARKER_LEN / 2, 0]
                    ], dtype=np.float32)
                    imgp = corners[0].reshape(-1, 2).astype(np.float32)
                    success, rvec, tvec = cv2.solvePnP(objp, imgp, CAM_MTX, DIST_COEFFS)
                    if success:
                        tvec = tvec.flatten()
                        txt = f"Cam XYZ: ({tvec[0]:.1f}, {-tvec[1]:.1f}, {tvec[2]:.1f})"
                        cv2.putText(fr, txt, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

                h, w = fr.shape[:2]
                cv2.drawMarker(fr, (w // 2, h // 2), (0, 255, 0), cv2.MARKER_CROSS, 20, 2)
                ret, jpeg = cv2.imencode('.jpg', fr)
                if ret:
                    yield (b'--frame\r\nContent-Type:image/jpeg\r\n\r\n' + jpeg.tobytes() + b'\r\n')

                time.sleep(0.03)
            except Exception as e:
                print(f"[ERROR] gen() 예외 발생: {e}")
                time.sleep(0.1)
                continue

    try:
        return Response(gen(), mimetype='multipart/x-mixed-replace;boundary=frame')
    except Exception as e:
        print(f"[ERROR] video_feed 예외 발생: {e}")
        return "Streaming error", 500

def stream_cam():
    global cap, latest_frame

    last_warn_ts = 0.0  # 경고 메시지 레이트 리밋용

    while True:
        if cap is None or not cap.isOpened():
            tmp = cv2.VideoCapture(0)  # 인덱스 0만 시도
            if tmp.isOpened():
                cap = tmp
                print("[카메라] 인덱스 0 연결됨")
            else:
                tmp.release()
                now = time.time()
                if now - last_warn_ts >= 5.0:
                    print("[경고] /dev/video0 열기 실패 → 재시도")
                    last_warn_ts = now
                time.sleep(1)
                continue

        ret, fr = cap.read()
        if not ret:
            cap.release()
            cap = None
            time.sleep(1)
            continue

        with lock:
            latest_frame = fr
        time.sleep(0.03)


def capture_tvec():
    time.sleep(0.5)
    with lock:
        fr = latest_frame.copy() if latest_frame is not None else None
    if fr is None:
        raise RuntimeError("프레임 없음")

    gray = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)  # ✅ 반드시 필요
    corners, ids, _ = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMS)
    if ids is None:
        raise RuntimeError("마커 없음")

    objp = np.array([
        [-MARKER_LEN/2, MARKER_LEN/2, 0],
        [ MARKER_LEN/2, MARKER_LEN/2, 0],
        [ MARKER_LEN/2,-MARKER_LEN/2, 0],
        [-MARKER_LEN/2,-MARKER_LEN/2, 0]
    ], dtype=np.float32)
    imgp = corners[0].reshape(-1, 2).astype(np.float32)
    _, rvec, tvec = cv2.solvePnP(objp, imgp, CAM_MTX, DIST_COEFFS)
    return tvec.flatten()

def euler_to_R(rx, ry, rz):
    a,b,c = np.deg2rad([rx,ry,rz])
    Rz = np.array([[np.cos(c), -np.sin(c), 0],
                   [np.sin(c),  np.cos(c), 0],
                   [0, 0, 1]])
    Ry = np.array([[np.cos(b), 0, np.sin(b)],
                   [0, 1, 0],
                   [-np.sin(b), 0, np.cos(b)]])
    Rx = np.array([[1, 0, 0],
                   [0, np.cos(a), -np.sin(a)],
                   [0, np.sin(a), np.cos(a)]])
    return Rz @ Ry @ Rx

def move_debug(mc, tgt, ori=None):
    tgt = [round(x, 1) for x in tgt]  # float 유지
    if ori:
        ori = [round(x, 1) for x in ori]
    else:
        ori = [0.0, 0.0, -45.0]

    print(f"\n▶ 이동 → XYZ=({tgt[0]},{tgt[1]},{tgt[2]}), Ori={ori}")

    before = mc.get_angles()
    if before is None:
        print("⚠️ 전 관절 각도 가져오기 실패")
        return None, -1
    print(f"  • 전 관절(°) = {[round(a, 1) for a in before]}")

    pose = tgt + ori
    res = mc.send_coords(pose, speed=SLOW_SPEED, mode=BLEND_MODE)
    time.sleep(5)

    after = mc.get_angles()
    if after is None:
        print("⚠️ 후 관절 각도 가져오기 실패")
        return None, -1
    print(f"  • 후 관절(°) = {[round(a, 1) for a in after]}")

    for i, (b, a) in enumerate(zip(before, after)):
        delta = round(a - b, 1)
        print(f"    ∆J{i+1} = {delta:+.1f}°")

    coords = mc.get_coords()
    if coords:
        xyz = [round(c, 1) for c in coords[:3]]
        print(f"  • 실제 XYZ={tuple(xyz)}, res={res}")
    else:
        print("⚠️ 최종 위치 가져오기 실패")

    return np.array(coords[:3]) if coords else None, res

def to_marker(mc, do_calib=True):
    global DT

    print("1) 운동 준비: 툴팁 → 마커 중앙")
    input()

    # --- ArUco 마커 인식 ---
    corners, ids, _ = aruco.detectMarkers(cv2.cvtColor(latest_frame, cv2.COLOR_BGR2GRAY), ARUCO_DICT, parameters=ARUCO_PARAMS)
    if ids is None:
        print("⚠️ 마커를 인식하지 못했습니다.")
        return

    rvec, tvec, _ = aruco.estimatePoseSingleMarkers(corners, MARKER_LEN, CAM_MTX, DIST_COEFFS)
    tvec_mean = np.mean(tvec, axis=0)[0]

    # --- 카메라 좌표계 → Base 기준 변환 ---
    tvec_fixed = np.array([
        round(-tvec_mean[1], 1),
        round(-tvec_mean[0], 1),
        round(tvec_mean[2], 1)
    ])

    coords = mc.get_coords()
    if coords is None:
        print("⚠️ get_coords() 실패")
        return
    ori = [round(x, 1) for x in coords[3:]]

    R_tool = euler_to_R(*ori)
    T_tool_in_base = np.round(R_tool @ T_TOOL2CAM, 1)

    marker_abs_pos = np.round(DT + tvec_fixed + T_tool_in_base, 1)
    current_coords = np.array(coords[:3])
    delta = marker_abs_pos - current_coords

    print(f"\n[현재 좌표] X={current_coords[0]:.1f}, Y={current_coords[1]:.1f}, Z={current_coords[2]:.1f}")
    print(f"[마커 좌표]  X={marker_abs_pos[0]:.1f}, Y={marker_abs_pos[1]:.1f}, Z={marker_abs_pos[2]:.1f}")
    print(f"[이동 Δ]     ΔX={delta[0]:+.1f}, ΔY={delta[1]:+.1f}, ΔZ={delta[2]:+.1f}")

    # --- 이동 목표 (Z 고정) ---
    correction_offset = np.array([47, -15.0, 0.0])
    
    target_coords = current_coords + delta + correction_offset
    target_coords[2] = 130.0
    print(f"▶ 이동 → X={target_coords[0]:.1f}, Y={target_coords[1]:.1f}, Z={target_coords[2]:.1f}")

    # --- 최종 이동 명령 ---
    mc.send_coords(target_coords.tolist() + ori, speed=SLOW_SPEED, mode=BLEND_MODE)

    # --- 이동 후 결과 좌표 및 오차 출력 ---
    time.sleep(3)
    final = mc.get_coords()
    if final:
        fxyz = np.round(np.array(final[:3]), 1)
        terr = np.round(fxyz - target_coords, 1)
        print(f"[이동 결과] XYZ=({fxyz[0]:.1f}, {fxyz[1]:.1f}, {fxyz[2]:.1f})")
        print(f"[오차]      ΔX={terr[0]:+.1f}, ΔY={terr[1]:+.1f}, ΔZ={terr[2]:+.1f}")
    else:
        print("⚠️ 이동 후 좌표 읽기 실패")

    # --- 선택적 DT 갱신 ---
    if do_calib:
        DT_new = current_coords + delta - (tvec_fixed + T_tool_in_base)
        DT_new = np.round(DT_new, 1)
        print(f"[새로운 DT] = {DT_new.tolist()}")
        ans = input("→ 이 값으로 저장할까요? (y/n): ").strip().lower()
        if ans == 'y':
            DT = DT_new
            save_calib()


def menu_calibrate():
    mc = MyCobot280('/dev/ttyJETCOBOT', 1000000)
    mc.thread_lock = True
    mc.send_angles([0]*6, FAST_SPEED)
    time.sleep(0.5)
    mc.send_angles(BASIC_POSE, FAST_SPEED)
    time.sleep(0.5)
    input("Static 보정: 툴팁→마커 올리고 Enter")

    Xc, Yc, Zc = capture_tvec()
    cam_vec_fixed = np.array([Xc, -Yc, Zc])

    coords = mc.get_coords()
    tp = np.array(coords[:3])
    ori = coords[3:6]
    R = euler_to_R(*ori)
    T_tool_in_base = R @ T_TOOL2CAM

    DT[:] = tp - (cam_vec_fixed + T_tool_in_base)
    save_calib()

def menu_verify_basic():
    print("=== 검증: 기본 포즈 ===")
    mc = MyCobot280('/dev/ttyJETCOBOT', 1000000); mc.thread_lock = True
    mc.send_angles(BASIC_POSE, FAST_SPEED); time.sleep(0.5)
    to_marker(mc, do_calib=False)

def menu_verify_pose2():
    print("=== 검증: 포즈2 ===")
    mc = MyCobot280('/dev/ttyJETCOBOT', 1000000); mc.thread_lock = True
    mc.send_angles(POSE2, FAST_SPEED); time.sleep(0.5)
    to_marker(mc, do_calib=False)

def menu_adjust():
    global DT
    print("현재 ΔT =", [round(x, 3) for x in DT])
    val = input("새 ΔT 입력 (쉼표): ")
    DT[:] = list(map(float, val.split(',')))
    save_calib()

def menu_joint6_test():
    mc = MyCobot280('/dev/ttyJETCOBOT', 1000000); mc.thread_lock = True
    cur = mc.get_angles()
    print("  • 현재 관절(°) =", [round((x),1) for x in cur])
    ang = float(input("회전할 J6 각도 (°): "))
    new = cur.copy(); new[5] = np.radians(ang)
    mc.send_angles(new, FAST_SPEED); time.sleep(0.5)
    print("  • 회전 후 =", [round((x),1) for x in mc.get_angles()])

def menu_test_simple_move():
    mc = MyCobot280('/dev/ttyJETCOBOT', 1000000); mc.thread_lock = True
    x = float(input("X 좌표: "))
    y = float(input("Y 좌표: "))
    z = float(input("Z 좌표: "))
    ori = [0.0, 0.0, -45.0]
    print("▶ 단순 이동 테스트 시작")
    cur, res = move_debug(mc, [x, y, z], ori)
    if res == 0:
        print("✅ 이동 성공")
    else:
        print("❌ 이동 실패")

def main():
    threading.Thread(target=stream_cam, daemon=True).start()
    threading.Thread(target=lambda: app.run(host='0.0.0.0', port=9816, debug=False), daemon=True).start()
    print(f"▶ 웹 스트리밍: http://{local_ip()}:9816")

    while True: 
        print("\n0)Joint-6 테스트  1)Static 보정  2)검증(Basic)  3)검증(Pose2)")
        print("4)ΔT 수동 입력     5)종료  6)단순 이동")

        c = input("선택> ").strip()
        if c == '0': menu_joint6_test()
        elif c == '1': menu_calibrate()
        elif c == '2': menu_verify_basic()
        elif c == '3': menu_verify_pose2()
        elif c == '4': menu_adjust()
        elif c == '5': cleanup(); sys.exit(0)  
        elif c == '6': menu_test_simple_move()
        else: print("❗ 잘못된 입력입니다.")

        # 카메라 및 포트 종료 → 스트리밍 재시작
        cleanup()

        threading.Thread(target=stream_cam, daemon=True).start()
        threading.Thread(target=lambda: app.run(host='0.0.0.0', port=9816, debug=False), daemon=True).start()
        print(f"▶ 웹 스트리밍: http://{local_ip()}:9816")


if __name__ == '__main__':
    main()
